# File Prompt Forge configuration
# Default provider can be overridden with --provider
provider: "google"
model: "gemini-2.5-pro" # Default model, can be overridden with --model

# URLs for each provider
provider_urls:
  openai: "https://api.openai.com/v1/responses"
  google: "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent"

# Test files used when no --file-a / --file-b are provided on the CLI.
test:
  # optional: if not supplied via --out, a default is composed from file_b
  # The <file_b_stem> and <model_name> placeholders will be replaced.
  out: "test/output/<file_b_stem>.<model_name>.fpf.response.txt"
  file_a: "test/input/sample_utf8.txt"
  file_b: "test/prompts/standard_prompt.txt"

# Optional prompt template (path or literal). Leave null to just concat files.
prompt_template: null

# Web search/tooling tuning (enable flag removed â€” web_search enforced in code)
web_search:
  # tuning: search_context_size, search_prompt, filters may be specified but disabling is ignored
  search_context_size: "low"
  search_prompt: "Perform a focused web search for up-to-date information relevant to the user's request. Summarize the most relevant findings and include citation links."

# Include extra fields in Responses API to capture web_search sources
include:
  - "web_search_call.action.sources"

# Reasoning configuration
reasoning:
  effort: "medium"

# Max completion tokens
max_completion_tokens: 14096
