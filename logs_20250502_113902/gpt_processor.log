2025-05-02 11:39:02,240 - gpt_processor - DEBUG - gpt_processor_main.py:main:259 - Parsed CLI args: {'config': None, 'log_file': None, 'verbose': True, 'prompt': ['C:/researcher3rd/test4fpf/filepromptforge\\filepromptforge\\prompts\\standard_prompt.txt'], 'input_dir': 'C:/researcher3rd/test4fpf/filepromptforge\\filepromptforge\\input', 'output_dir': 'C:/researcher3rd/test4fpf/filepromptforge\\filepromptforge\\output', 'model': None, 'temperature': None, 'max_tokens': None}
2025-05-02 11:39:02,240 - gpt_processor - DEBUG - gpt_processor_main.py:main:279 - Configuration loaded from C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\default_config.yaml: {'prompts_dir': 'C:/researcher3rd/test4fpf/filepromptforge\\filepromptforge\\prompts', 'input_dir': 'C:/researcher3rd/test4fpf/filepromptforge\\filepromptforge\\input', 'output_dir': 'C:/researcher3rd/test4fpf/filepromptforge\\filepromptforge\\output', 'provider': 'OpenRouter', 'openai': <__main__.Config.ProviderConfig object at 0x0000019C63AB1580>, 'openrouter': <__main__.Config.ProviderConfig object at 0x0000019C63EC36E0>}
2025-05-02 11:39:02,245 - gpt_processor - DEBUG - gpt_processor_main.py:main:308 - Prompt files: ['C:/researcher3rd/test4fpf/filepromptforge\\filepromptforge\\prompts\\standard_prompt.txt']
2025-05-02 11:39:02,245 - gpt_processor - DEBUG - gpt_processor_main.py:main:309 - Input directory: C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\input
2025-05-02 11:39:02,245 - gpt_processor - DEBUG - gpt_processor_main.py:main:310 - Output directory: C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\output
2025-05-02 11:39:02,245 - gpt_processor - DEBUG - gpt_processor_main.py:main:322 - System prompt content:
You are ChatGPT, a large language model trained by OpenAI. Provide clear and concise answers to the user's queries.
2025-05-02 11:39:02,245 - gpt_processor - DEBUG - gpt_processor_main.py:main:331 - Input files: ['standard_prompt.txt']
2025-05-02 11:39:02,245 - gpt_processor - DEBUG - gpt_processor_main.py:process_file:346 - Processing file: C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\input\standard_prompt.txt
2025-05-02 11:39:02,247 - gpt_processor - DEBUG - gpt_processor_main.py:read_file:143 - Reading file 'C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\input\standard_prompt.txt'
2025-05-02 11:39:02,247 - gpt_processor - DEBUG - gpt_processor_main.py:read_file:146 - Read file 'C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\input\standard_prompt.txt', length 32
2025-05-02 11:39:02,247 - gpt_processor - DEBUG - gpt_processor_main.py:process_file:348 - User prompt length for 'C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\input\standard_prompt.txt': 32
2025-05-02 11:39:02,661 - gpt_processor - DEBUG - gpt_processor_main.py:send_prompt:195 - API request payload (OpenRouter): model=, temperature=0.7, max_tokens=1500, messages=[{'role': 'system', 'content': "You are ChatGPT, a large language model trained by OpenAI. Provide clear and concise answers to the user's queries."}, {'role': 'user', 'content': 'talk about tigers how many left?'}]
2025-05-02 11:39:03,015 - gpt_processor - ERROR - gpt_processor_main.py:send_prompt:208 - OpenRouter API error: Error code: 400 - {'error': {'message': 'No models provided', 'code': 400}, 'user_id': 'user_2nlT1S5wIPbSHvedWRsMkWS8ezF'}
Traceback (most recent call last):
  File "C:\researcher3rd\fpf\gpt_processor_main.py", line 197, in send_prompt
    response = client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Roaming\Python\Python312\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Roaming\Python\Python312\site-packages\openai\resources\chat\completions\completions.py", line 925, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1239, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\AppData\Roaming\Python\Python312\site-packages\openai\_base_client.py", line 1034, in request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': 'No models provided', 'code': 400}, 'user_id': 'user_2nlT1S5wIPbSHvedWRsMkWS8ezF'}
2025-05-02 11:39:03,020 - gpt_processor - WARNING - gpt_processor_main.py:send_prompt:209 - Generating mock response due to OpenRouter API error.
2025-05-02 11:39:03,020 - gpt_processor - DEBUG - gpt_processor_main.py:write_file:154 - Writing file 'C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\output\response_standard_prompt.txt' with content length 50
2025-05-02 11:39:03,020 - gpt_processor - DEBUG - gpt_processor_main.py:write_file:157 - Wrote file 'C:/researcher3rd/test4fpf/filepromptforge\filepromptforge\output\response_standard_prompt.txt', length 50
