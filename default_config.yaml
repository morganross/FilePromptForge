llm_endpoint_url: http://localhost:4000
input_file: test/input/sample_utf8.txt
output_dir: test/output
prompts_dir: test/prompts
provider: OpenAI
openai:
  model: gemini/gemini-2.5-flash
  temperature: 0.7
  max_tokens: 15000
grounding:
  enabled: true
  max_results: 10
  search_prompt: 'Incorporate and cite these sources:'
  allow_external_fallback: false
  approve_tool_calls: false
